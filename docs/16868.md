# åŸºäº Android å¹³å°çš„ TensorFlow Lite å›¾åƒåˆ†ç±»

> åŸæ–‡:[https://dev . to/bright devs/image-class ification-with-tensor flow-lite-on-Android-3k HL](https://dev.to/brightdevs/image-classification-with-tensorflow-lite-on-android-3khl)

æ­£å¦‚æˆ‘åœ¨æœ€è¿‘çš„[åšå®¢æ–‡ç« ](https://brightinventions.pl/blog/are-we-ready-for-deep-learning-on-mobile-devices/)ä¸­æ‰€åˆ—ï¼Œç›´æ¥åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šè¿›è¡Œæ¨ç†æ¯”ä½¿ç”¨äº‘è§£å†³æ–¹æ¡ˆæœ‰å¾ˆå¤šä¼˜åŠ¿ã€‚ç”±äºç§»åŠ¨è®¾å¤‡çš„è®¡ç®—é™åˆ¶ï¼Œæˆ‘ä»¬æ— æ³•å°†æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ç§»æ¤åˆ°ç§»åŠ¨è®¾å¤‡ä¸Šã€‚ä¸å¹¸çš„æ˜¯ï¼Œå®ƒä»¬ä¸­çš„è®¸å¤šä¸èƒ½åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå·¥ä½œï¼Œä½†è¿™æ²¡å…³ç³»ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸ä¸éœ€è¦è¿™äº›ç¬¨é‡çš„ç§»åŠ¨è®¾å¤‡ã€‚åœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç®€å•çš„ Android åº”ç”¨ç¨‹åºï¼Œå®ƒå°†åˆ©ç”¨åœ¨ ImageNet ä¸Šé¢„å…ˆè®­ç»ƒçš„ [MobileNetV2](https://arxiv.org/abs/1801.04381) ã€‚

[![](../Images/8bf8542f2d156bb0a51dea9949dfa5e6.png)T2ã€‘](https://res.cloudinary.com/practicaldev/image/fetch/s--xxQEOUFI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/girm9r0x52frcwvlqflw.jpg)

## è®©æˆ‘ä»¬æŠŠæ‰‹å¼„è„å§...

åœ¨æˆ‘ä»¬çš„ Android åº”ç”¨ç¨‹åºé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°† TFLite ä¾èµ–é¡¹æ·»åŠ åˆ°`build.gradle`æ–‡ä»¶ä¸­ã€‚

```
implementation 'org.tensorflow:tensorflow-lite:1.13.1' 
```

å’Œä¸‹é¢æåˆ°çš„é˜²æ­¢å‹ç¼©æ¨¡å‹çš„ä»£ç ç‰‡æ®µã€‚

```
aaptOptions {  
    noCompress "tflite"  
    noCompress "lite"  
} 
```

ä¸‹ä¸€æ­¥æ˜¯å¾—åˆ°å›¾åƒåˆ†ç±»é—®é¢˜çš„æ¨¡å‹ã€‚ä¸€ç§æ–¹æ³•æ˜¯åˆ›å»ºä½ è‡ªå·±çš„æˆ–è€…ä»[è¿™é‡Œ](https://www.tensorflow.org/lite/guide/hosted_models)æ‹¿ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„ï¼Œç„¶åæŠŠå®ƒæ”¾åˆ°`assets`æ–‡ä»¶å¤¹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨æˆ‘ä¸ºäº†è¿™ä¸ªæ¼”ç¤ºè€Œåˆ›å»ºçš„å®šåˆ¶çš„é¢„åŸ¹è®­ MobileNetV2ã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†èƒ½å¤Ÿæˆ–è€…è‡³å°‘åº”è¯¥åŒºåˆ†ğŸŒŠ*é£ç­å†²æµªã€å¸†æ¿*å’Œ*å†²æµª*ğŸ„â€â™‚ï¸.æ‚¨å¯ä»¥ä»æˆ‘çš„ [git åº“](https://github.com/ares97/tflitedemo-mobilenetv2-imagenet-classification/tree/master/app/src/main/assets)ä¸‹è½½è¿™ä¸ªæ¨¡å‹å’Œæ ‡ç­¾ã€‚

[![](../Images/8622fc92fb061343e0e3362ad48e5201.png)T2ã€‘](https://res.cloudinary.com/practicaldev/image/fetch/s--tL-cvr_H--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/ghtn0j1rwnhqkrbvg4q5.jpg)

### [](#dive-into-the-code)æ½œå…¥ä»£ç 

ä¸ºäº†åˆ©ç”¨å‡†å¤‡å¥½çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä»¥æŸç§æ–¹å¼å°†å…¶å¯¼å…¥ä»£ç ã€‚è®©æˆ‘ä»¬ä½¿ç”¨`tf.lite.Interpreter`ç•Œé¢è¿›è¡Œå»ºæ¨¡ã€‚

ä½ å¯ä»¥ç”¨å¾ˆå¤šæ–¹æ³•è®¾ç½®ä¸€ä¸ªè§£é‡Šå™¨ï¼Œåœ¨ [TF ç½‘ç«™](https://www.tensorflow.org/lite/models/image_classification/android)ä¸Šæ¨èçš„ä¸€ä¸ªå°±æ˜¯åˆ©ç”¨`MappedByteBuffer`ã€‚

```
@Throws(IOException::class)  
private fun getModelByteBuffer(assetManager: AssetManager, modelPath: String): MappedByteBuffer {  
    val fileDescriptor = assetManager.openFd(modelPath)  
    val inputStream = FileInputStream(fileDescriptor.fileDescriptor)  
    val fileChannel = inputStream.channel  
    val startOffset = fileDescriptor.startOffset  
    val declaredLength = fileDescriptor.declaredLength  
    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength) 
} 
```

ç„¶å...

```
model = Interpreter(loadModelFile(activity)) 
```

ä¸å¹¸çš„æ˜¯ï¼Œä½¿ç”¨`MappedByteBuffer`ä½œä¸ºå‚æ•°å·²ç»è¢«å¦å†³ï¼Œå¹¶å°†åœ¨æœªæ¥çš„ç‰ˆæœ¬ä¸­è¢«åˆ é™¤ï¼Œä½†ä½ å¯ä»¥é€šè¿‡æä¾› ByteBuffer æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿™å°±åƒè°ƒç”¨`loadModelFile`æ–¹æ³•ä¸Šçš„`.asReadOnlyBuffer()`ä¸€æ ·ç®€å•ã€‚

ä¸‹ä¸€æ­¥æ˜¯è¯»å–å¸¦æœ‰æ ‡ç­¾çš„æ–‡ä»¶ã€‚æ‚¨å¯ä»¥ä½¿ç”¨
è½»æ¾è·å–å®ƒä»¬

```
@Throws(IOException::class)  
private fun getLabels(assetManager: AssetManager, labelPath: String): List<String> {  
    val labels = ArrayList<String>()  
    val reader = BufferedReader(InputStreamReader(assetManager.open(labelPath)))  
    while (true) {
        val label = reader.readLine() ?: break
        labels.add(label)
    }  
    reader.close()  
    return labels  
} 
```

æœ€åä¸€ä»¶äº‹æ˜¯åˆ›å»ºä¸€ä¸ªæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†ä¸€ä¸ªå›¾åƒä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ ‡ç­¾åˆ—è¡¨ï¼Œè¿™äº›æ ‡ç­¾å…·æœ‰åˆ†é…ç»™å®ƒä»¬çš„æ¦‚ç‡ã€‚

```
fun recognize(bitmap: Bitmap): List<Recognition>{ 
```

å› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹æœŸæœ›ç²¾ç¡®çš„è¾“å…¥å½¢çŠ¶(224x224 åƒç´ ),æ‰€ä»¥æˆ‘ä»¬éœ€è¦é‡æ–°ç¼©æ”¾äº¤ä»˜çš„ä½å›¾ä»¥é€‚åº”è¿™äº›çº¦æŸã€‚

```
 val scaledBitmap =  Bitmap.createScaledBitmap(bitmap, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE, false) 
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºé€‚å½“å¤§å°çš„ byteBufferï¼Œå®ƒå°†ä½œä¸ºå‚æ•°ä¼ é€’ç»™æ¨¡å‹ã€‚

```
 val byteBuffer = ByteBuffer  
        .allocateDirect(  
                    BATCH_SIZE *         // amount of images per single processing
                    MODEL_INPUT_SIZE *   // img height
                    MODEL_INPUT_SIZE *   // img width
                    BYTES_PER_CHANNEL *  // size of float = 4
                    PIXEL_SIZE           // r+g+b = 1+1+1
      )  
        .apply { order(ByteOrder.nativeOrder()) } // force device's native order (BIG_ENDIAN or LITTLE_ENDIAN) 
```

å¹¶å°†å›¾åƒæ•°æ®ä½œä¸º*æµ®ç‚¹æ•°*è½½å…¥`byteByffer`ã€‚ä¸ºäº†è§£ç ä½å›¾ä¸­æ¯ä¸ªåƒç´ çš„é¢œè‰²(å¿½ç•¥ alpha ),æˆ‘ä»¬éœ€è¦å±è”½æœ€ä½æœ‰æ•ˆçš„ 8 ä½åŠå…¶å€æ•°ã€‚

```
 val pixelValues = IntArray(MODEL_INPUT_SIZE * MODEL_INPUT_SIZE)  
    bitmap.getPixels(pixelValues, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)  

    var pixel = 0  
    for (i in 0 until MODEL_INPUT_SIZE) {  
        for (j in 0 until MODEL_INPUT_SIZE) {  
            val pixelValue = pixelValues[pixel++]  
            byteBuffer.putFloat((pixelValue shr 16 and 0xFF) / 255f)  
            byteBuffer.putFloat((pixelValue shr 8 and 0xFF) / 255f)  
            byteBuffer.putFloat((pixelValue and 0xFF) / 255f)  
        }  
    } 
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å°† *byteBuffer* ä¼ é€’ç»™æ¨¡å‹ã€‚è§£é‡Šå™¨æœŸæœ›ç»“æœçš„ç¬¬äºŒä¸ªå˜å…ƒå®¹å™¨ï¼Œå®ƒæ˜¯*æ•°ç»„*åˆ°*æµ®ç‚¹æ•°ç»„*(æ¯ä¸ªå›¾åƒçš„*æ•°ç»„*ï¼Œæ¯ä¸ªå›¾åƒå°†åŒ…å«æ¦‚ç‡çš„*æµ®ç‚¹æ•°ç»„*)ã€‚

```
 val results = Array(BATCH_SIZE) { FloatArray(labels.size) }
    model.run(byteBuffer, results)
    return parseResults(results)
} 
```

æœ€åä¸€æ­¥æ˜¯å°†æ¦‚ç‡ä¸é€‚å½“çš„ç±»ç»‘å®šã€‚

```
private fun parseResults(result: Array<FloatArray>): List<Recognition> {  

    val recognitions = mutableListOf<Recognition>()  

    labels.forEachIndexed { index, label ->  
        val probability = result[0][index]  
        recognitions.add(Recognition(label, probability))  
    }  

  return recognitions.sortedByDescending { it.probability }  
} 
```

å…¶ä¸­*è¯†åˆ«*æ˜¯æˆ‘ä»¬ç®€é™‹çš„ç»“æœæ•°æ®ç±»ã€‚

```
data class Recognition(  
    val name: String,  
    val probability: Float  
) {  
    override fun toString() =  
        "$name : ${probability*100}%"  
} 
```

###### [](#dont-forget-that-there-are-many-things-you-should-consider-to-make-it-work-well-ie-handling-a-camera-orientation-or-using-posttraining-quantization-if-you-need-higher-speed-with-a-bit-lower-accuracy-and-lighter)ä¸è¦å¿˜è®°ï¼Œè¦è®©å®ƒå·¥ä½œå¾—æ›´å¥½ï¼Œä½ éœ€è¦è€ƒè™‘å¾ˆå¤šäº‹æƒ…ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä½ éœ€è¦æ›´é«˜çš„é€Ÿåº¦ã€ç¨ä½çš„ç²¾åº¦å’Œæ›´è½»çš„é‡é‡ï¼Œä½ éœ€è¦å¤„ç†æ‘„åƒæœºçš„æ–¹å‘æˆ–ä½¿ç”¨è®­ç»ƒåé‡åŒ–ã€‚

## [](#its-showtime)å¥½æˆä¸Šåœºäº†ï¼

ä¸Šé¢çš„ä»£ç æ˜¯è®© TFLite ä¸ºæˆ‘ä»¬è§£å†³*å›¾åƒåˆ†ç±»*é—®é¢˜çš„æç®€ç‰ˆæœ¬ã€‚ä½¿ç”¨æä¾›çš„æ¨¡å‹ï¼Œæ‚¨å¯ä»¥æˆåŠŸåœ°å¯¹è¿™ç¯‡åšå®¢æ–‡ç« ä¸­çš„æ‰€æœ‰ç…§ç‰‡è¿›è¡Œåˆ†ç±»ã€‚ğŸ“¸
ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°è¯•ç©[ã€‚](https://github.com/ares97/tflitedemo-mobilenetv2-imagenet-classification)

[![](../Images/183ece48766c352feba30a7f42b767dc.png)T2ã€‘](https://res.cloudinary.com/practicaldev/image/fetch/s--UClo-acB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/o8yx83vtewsrlioc9jdm.png)

æœ€åˆå‘è¡¨äº brightinventions.pl

ä½œè€…æ‹‰å¤šæ–¯ç“¦å¤«Â·ç´¢ç»´æ–¯åŸºï¼Œè½¯ä»¶å·¥ç¨‹å¸ˆ@å…‰æ˜å‘æ˜